What exactly Deployments are and how they are different from Services

When it comes to managing the stateless services which generally run on the cluster,
the Kubernetes deployments is something that is widely considered.
The prime objective is very simple and i.e. to manage the pods which are similar.
In addition to this, upgrading these pods is also done through the deployment approach.
Generally, a deployment controller is responsible for offering the updates which are declarative in nature
for both Replica sets as well as for the Pods. When the users describe a desired state in the object associated with the deployment,
the controller is always responsible for modifying the real state to the one which is desired and this is done at a controller rate.
This is pretty different as compare to that in Services. For creating a new replica sets, Deployments can easily be defined.
It is also possible to move the existing deployments and control other new resources through it.

    It must be kept in mind that the Kubernetes cannot manage the replica sets which are owned by the deployment.
    The cases which are already used are necessary to be covered by simply manipulating the object within the deployment.
    
 -------------------------------------------------------------
 What is Kubernetes Services and how it is different from Deployments

The Service is generally regarded as the abstraction which is responsible for clearly defining the pods which are logical.
It also defines the policy for accessing them and the same is known as a micro-service.
There is no such approach or a micro-deployment available. There is a Label selector which determines the pods which services target.
Service without selector is not possible.
However, on the other side, Deployment doesn’t depend on any selector for accomplish the task in a reliable manner.
Next major difference is Decoupling process can easily be opted in the Services and Deployments doesn’t allow the same. 

    For all the native applications, there is an API which updates itself automatically when a change is seen in the pods available within a service.
    The non-native applications, the same approach depends on a virtual-IP based bridge to the Services. The same is responsible for performing tasks such as redirecting the apps.



-------------------------------------
Deployments:

A Deployment is an object in the cluster that represents a group of a set of pods running, a logical group with some management capabilities tied to it. Deployments have semantics for the state of the cluster.

For example, imagine there is a need to support monitoring metrics for a set of services in your cluster. The ops team developed a docker image called metrics-analyzer 1.0.0 that receives the configuration of where are all the agents that need gathering, how frequently should the component gather and what endpoint per agent provide metrics.

Now if the team just writes a Pod ma.yml to deploy that to kubernetes, they will likely end up with a single pod running in whatever node kubernetes can schedule it. If the operation fails, or the metrics-analyzer needs to be upgraded, or kubernetes needs to reassign resources (or many other events I am omitting) the pod will need to be evicted causing downtime to metrics gathering. That event can cause a service deprecation, executives might call the team saying: We need metrics, just fix it.

A deployment can help you create a group of metrics-analyzer pods matching them with labels to be able to manage your metrics-analyzer without caring about every single replica running.

Essentially deployments tell Kubernetes how to match the containers using labels, the number of replicas needed to run and how to upgrade them. Upgrades are a major topic that this post discussed better than me Kubernetes deployment strategies - Container Solutions

Also, in the deployment spec, the pod spec can be also specified to avoid having to handle different resource files for the same goal. In the end, the team just needs to deploy metrics-analyzer right?.

Services:

Services, on the other hand, allow groupings of pods for the primary purpose of network communication.

The domain of services is to provide a set of rules for the accessibility of a set of pods. Some examples of the rules you set while specifying services are:

    Which pods match the service group.
    What type of network address will service use?
        Nodeport. All nodes in the cluster have a port dedicated to forward to pods matching the service.
        Cluster IP. There is a dedicated cluster IP for accessing the pods matching the service.
        Load Balancer. To expose the pods outside of the network cluster with an external network LB.
        External name. To expose an external URI source with a qualified name in the cluster (like db-service goes to 32dfs-324qa.domain.com).
    Protocols and ports. Where traffic should be redirected when there are requests to the service name
    The actual service network name like metrics-analyzer.

Services allow other pods to communicate with components of the cluster without the need of knowing their actual IP in the cluster.

So as you can see Deployments have a delivery semantic to it, they matter when you need to increase replicas or decrease it when you need to deliver a new version, they specify how the process of upgrading pods work.

Services are a networking construct mostly. They model how are the pods accessed through the cluster network and from the outside world into the cluster network.
-------------------------------------------------------------------------------------
More Answers Below

    What is the difference between POD and deployment in Kubernetes?
    What is the difference between SAP and Kubernetes?
    What are Kubernetes deployments?
    What is the relationship between CoreOS and Kubernetes?
    What are pros and cons of Kubernetes?

-----------------------------------------------------------------------
Deployment:

From a conceptual level Deployments define how your application will be deployed. It will define how many instances of the applications should be running when deploying the application in Kubernetes. It also defines other parameters and settings used to help a running application.

When a deployment is run in Kubernetes it will create pods. A pod is made up of one or more containers (most popular is Docker). In many cases, there is just one container per pod and that is typically your application in the form of a running Docker image. To relate to a container to the traditional server deployments, a container operates similarly to a Virtual Machine (VM) or physical server.

If your deployment states that there should be more than 1 of your applications running (High Availability or HA), then more pod will be created until the application scale requirement has been fulfilled.

Now that you have 1 or more instances of your application running, you need a way to connect to those running applications. This is where “Services” come into play.

Services:

Service definitions in Kubernetes are really just a load balancer inside Kubernetes. When an application request is made it is passed to the application service, which knows what applications (pods) are available and how to send traffic to that application. Typically, the services send traffic in a round-robin manner, which means requests are spread across all the running applications (pods).

In my experience, both Docker and Kubernetes have reduced the development time for software teams and made application management easier then what was done in the past. If you write your software correctly it will scale nicely with Kubernetes.

If you would like to see Docker containers working with Kubernetes in action you can test it out at http://BroadIQ.com. Also, take a look at “The Simple guide to running Rocket.Chat” (https://medium.com/@jlutz_72580/...) article that walks you through the steps of deploying a docker container application on Kubernetes.
